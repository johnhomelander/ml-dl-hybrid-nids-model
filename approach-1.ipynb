{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 15:23:07.224918: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-08 15:23:07.231351: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-08 15:23:07.281364: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-08 15:23:07.324485: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744105987.365630    4831 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744105987.377897    4831 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744105987.547981    4831 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744105987.548025    4831 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744105987.548030    4831 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744105987.548034    4831 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-08 15:23:07.567010: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest\n",
    "from sklearn.decomposition import PCA\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataset shape:           Destination Port   Flow Duration   Total Fwd Packets  \\\n",
      "0                       88             640                   7   \n",
      "1                       88             900                   9   \n",
      "2                       88            1205                   7   \n",
      "3                       88             511                   7   \n",
      "4                       88             773                   9   \n",
      "...                    ...             ...                 ...   \n",
      "2830738                 80          590930                   2   \n",
      "2830739                 80         1187988                   2   \n",
      "2830740                 80              10                   1   \n",
      "2830741                138              19                  10   \n",
      "2830742                 80         4751966                   2   \n",
      "\n",
      "          Total Backward Packets  Total Length of Fwd Packets  \\\n",
      "0                              4                          440   \n",
      "1                              4                          600   \n",
      "2                              4                         2776   \n",
      "3                              4                          452   \n",
      "4                              4                          612   \n",
      "...                          ...                          ...   \n",
      "2830738                        0                            0   \n",
      "2830739                        0                            0   \n",
      "2830740                        9                            6   \n",
      "2830741                        0                         2370   \n",
      "2830742                        0                            0   \n",
      "\n",
      "          Total Length of Bwd Packets   Fwd Packet Length Max  \\\n",
      "0                                 358                     220   \n",
      "1                                2944                     300   \n",
      "2                                2830                    1388   \n",
      "3                                 370                     226   \n",
      "4                                2944                     306   \n",
      "...                               ...                     ...   \n",
      "2830738                             0                       0   \n",
      "2830739                             0                       0   \n",
      "2830740                            54                       6   \n",
      "2830741                             0                     237   \n",
      "2830742                             0                       0   \n",
      "\n",
      "          Fwd Packet Length Min   Fwd Packet Length Mean  \\\n",
      "0                             0                62.857143   \n",
      "1                             0                66.666667   \n",
      "2                             0               396.571429   \n",
      "3                             0                64.571429   \n",
      "4                             0                68.000000   \n",
      "...                         ...                      ...   \n",
      "2830738                       0                 0.000000   \n",
      "2830739                       0                 0.000000   \n",
      "2830740                       6                 6.000000   \n",
      "2830741                     237               237.000000   \n",
      "2830742                       0                 0.000000   \n",
      "\n",
      "          Fwd Packet Length Std  ...   min_seg_size_forward  Active Mean  \\\n",
      "0                    107.349008  ...                     20          0.0   \n",
      "1                    132.287566  ...                     20          0.0   \n",
      "2                    677.274651  ...                     20          0.0   \n",
      "3                    110.276708  ...                     20          0.0   \n",
      "4                    134.933317  ...                     20          0.0   \n",
      "...                         ...  ...                    ...          ...   \n",
      "2830738                0.000000  ...                     32          0.0   \n",
      "2830739                0.000000  ...                     32          0.0   \n",
      "2830740                0.000000  ...                     20          0.0   \n",
      "2830741                0.000000  ...                     20          0.0   \n",
      "2830742                0.000000  ...                     32          0.0   \n",
      "\n",
      "          Active Std   Active Max   Active Min  Idle Mean   Idle Std  \\\n",
      "0                0.0            0            0        0.0        0.0   \n",
      "1                0.0            0            0        0.0        0.0   \n",
      "2                0.0            0            0        0.0        0.0   \n",
      "3                0.0            0            0        0.0        0.0   \n",
      "4                0.0            0            0        0.0        0.0   \n",
      "...              ...          ...          ...        ...        ...   \n",
      "2830738          0.0            0            0        0.0        0.0   \n",
      "2830739          0.0            0            0        0.0        0.0   \n",
      "2830740          0.0            0            0        0.0        0.0   \n",
      "2830741          0.0            0            0        0.0        0.0   \n",
      "2830742          0.0            0            0        0.0        0.0   \n",
      "\n",
      "          Idle Max   Idle Min   Label  \n",
      "0                0          0  BENIGN  \n",
      "1                0          0  BENIGN  \n",
      "2                0          0  BENIGN  \n",
      "3                0          0  BENIGN  \n",
      "4                0          0  BENIGN  \n",
      "...            ...        ...     ...  \n",
      "2830738          0          0  BENIGN  \n",
      "2830739          0          0  BENIGN  \n",
      "2830740          0          0  BENIGN  \n",
      "2830741          0          0  BENIGN  \n",
      "2830742          0          0  BENIGN  \n",
      "\n",
      "[2830743 rows x 79 columns]\n",
      "['BENIGN' 'FTP-Patator' 'SSH-Patator' 'Bot' 'PortScan'\n",
      " 'Web Attack � Brute Force' 'Web Attack � XSS'\n",
      " 'Web Attack � Sql Injection' 'DoS slowloris' 'DoS Slowhttptest'\n",
      " 'DoS Hulk' 'DoS GoldenEye' 'Heartbleed' 'DDoS' 'Infiltration']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "# Set the directory containing your CSV files\n",
    "data_dir = \"datasets/MachineLearningCVE\"  # change to your directory path\n",
    "\n",
    "# Use glob to create a list of CSV file paths\n",
    "csv_files = glob.glob(os.path.join(data_dir, \"*.csv\"))\n",
    "\n",
    "# Initialize an empty list to store individual DataFrames\n",
    "df_list = []\n",
    "\n",
    "# Loop through the files, read each one, and append to the list\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    # Optionally: add a column to indicate the source file or attack type if needed.\n",
    "    df_list.append(df)\n",
    "\n",
    "# Concatenate all the DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(df_list, ignore_index=True)\n",
    "print(\"Combined dataset shape:\", combined_df)\n",
    "print(combined_df[' Label'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data Loading and Initial Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BENIGN' 'FTP-Patator' 'SSH-Patator' 'Bot' 'PortScan'\n",
      " 'Web Attack � Brute Force' 'Web Attack � XSS'\n",
      " 'Web Attack � Sql Injection' 'DoS slowloris' 'DoS Slowhttptest'\n",
      " 'DoS Hulk' 'DoS GoldenEye' 'Heartbleed' 'DDoS' 'Infiltration']\n",
      "[ 0  7 11  1 10 12 14 13  6  5  4  3  8  2  9]\n"
     ]
    }
   ],
   "source": [
    "# Replace the file name with your actual dataset path.\n",
    "df = combined_df\n",
    "\n",
    "# Drop irrelevant columns (adjust as needed)\n",
    "df.drop(['Flow ID', 'Source IP', 'Destination IP', 'Timestamp'], axis=1, inplace=True, errors='ignore')\n",
    "\n",
    "# Handle missing values by replacing them with median values (for numeric columns)\n",
    "# df.drop(' Label',axis=1).fillna(df.drop(' Label',axis=1).median(), inplace=True)\n",
    "\n",
    "# Compute the median for numeric columns only\n",
    "numeric_medians = df.select_dtypes(include=[np.number]).median()\n",
    "\n",
    "# Fill missing values for numeric columns using the computed medians\n",
    "df.fillna(numeric_medians, inplace=True)\n",
    "\n",
    "# Encode labels to numeric values (Assuming 'Label' is the column name)\n",
    "label_encoder = LabelEncoder()\n",
    "print(df[' Label'].unique())\n",
    "df[' Label'] = label_encoder.fit_transform(df[' Label'])\n",
    "\n",
    "# Replace infinite values with NaN\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Remove rows with NaN values if necessary\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Separate features and labels\n",
    "X = df.drop(' Label', axis=1)\n",
    "y = df[' Label']\n",
    "\n",
    "print(df[' Label'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Advanced Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features selected by Mutual Information: [' Destination Port', ' Flow Duration', 'Total Length of Fwd Packets', ' Total Length of Bwd Packets', ' Fwd Packet Length Max', 'Bwd Packet Length Max', ' Bwd Packet Length Mean', 'Flow Bytes/s', ' Flow IAT Max', ' Fwd IAT Max', ' Max Packet Length', ' Packet Length Mean', ' Packet Length Std', ' Packet Length Variance', ' Average Packet Size', ' Avg Bwd Segment Size', ' Subflow Fwd Bytes', ' Subflow Bwd Bytes', 'Init_Win_bytes_forward', ' Init_Win_bytes_backward']\n",
      "Explained variance ratio by PCA components:\n",
      " [0.42936758 0.1363219  0.0849158  0.07294257 0.06018655 0.05523184\n",
      " 0.0509684  0.04493896 0.03229192 0.01347312]\n"
     ]
    }
   ],
   "source": [
    "# 2.1: Statistical Feature Selection using Mutual Information\n",
    "# Select top 20 features based on Mutual Information\n",
    "selector_mi = SelectKBest(score_func=mutual_info_classif, k=20)\n",
    "X_mi = selector_mi.fit_transform(X, y)\n",
    "selected_features_mi = X.columns[selector_mi.get_support(indices=True)]\n",
    "print(\"Features selected by Mutual Information:\", list(selected_features_mi))\n",
    "\n",
    "# 2.2: Dimensionality Reduction using PCA\n",
    "# First, scale the MI-selected features\n",
    "scaler_pca = StandardScaler()\n",
    "X_mi_scaled = scaler_pca.fit_transform(X_mi)\n",
    "\n",
    "# Apply PCA to reduce dimensions (e.g., to 10 components)\n",
    "pca = PCA(n_components=10)\n",
    "X_pca = pca.fit_transform(X_mi_scaled)\n",
    "print(\"Explained variance ratio by PCA components:\\n\", pca.explained_variance_ratio_)\n",
    "\n",
    "# We'll use PCA-reduced features as our final feature set\n",
    "X_final = X_pca\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Final Data Scaling, Balancing, and Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete. Training samples: 27255840 Test samples: 6813960\n"
     ]
    }
   ],
   "source": [
    "# Further standardize the final features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_final)\n",
    "\n",
    "# Balance the dataset using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
    "\n",
    "# Split the data into training and testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "print(\"Preprocessing complete. Training samples:\", X_train.shape[0], \"Test samples:\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: ML Classifier Training (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/john/Files/R&D Project/models/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [20:17:23] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"lambda_\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94    454511\n",
      "           1       0.98      1.00      0.99    453189\n",
      "           2       0.99      0.99      0.99    453177\n",
      "           3       0.96      0.98      0.97    454702\n",
      "           4       0.99      0.98      0.99    454314\n",
      "           5       0.99      0.99      0.99    454606\n",
      "           6       0.99      0.98      0.98    453653\n",
      "           7       1.00      1.00      1.00    454136\n",
      "           8       1.00      1.00      1.00    455097\n",
      "           9       0.99      1.00      0.99    453657\n",
      "          10       0.96      0.98      0.97    453831\n",
      "          11       1.00      1.00      1.00    454814\n",
      "          12       0.78      0.51      0.62    454619\n",
      "          13       0.98      1.00      0.99    454505\n",
      "          14       0.63      0.85      0.73    455149\n",
      "\n",
      "    accuracy                           0.94   6813960\n",
      "   macro avg       0.95      0.94      0.94   6813960\n",
      "weighted avg       0.95      0.94      0.94   6813960\n",
      "\n",
      "XGBoost Confusion Matrix:\n",
      " [[413245   5836    810   5060   3070    855   1384    336      4   4470\n",
      "   15789    167   1109   1083   1293]\n",
      " [   407 451513      0      0      0      0      0      0      0      0\n",
      "    1269      0      0      0      0]\n",
      " [   363      1 450791   1665    313     22      1      8      0     13\n",
      "       0      0      0      0      0]\n",
      " [   563      0   2332 445698    156    338   2084      0      0     30\n",
      "       0      0      0   3481     20]\n",
      " [   842      0   2264   2370 446639      1    395      5      0      0\n",
      "       0      0      1   1795      2]\n",
      " [   619      0    280    976     10 451010   1405      0      0      0\n",
      "       0      5    119     43    139]\n",
      " [   889      0    150   7455     27   1889 442879      0      0      0\n",
      "       0      1     95      3    265]\n",
      " [    27      0      0      0      0      0      2 454085      0      0\n",
      "       0      0     21      0      1]\n",
      " [     0      0      0      0      0      0      0      0 455097      0\n",
      "       0      0      0      0      0]\n",
      " [   725      0      0      0      0      0      0      0      0 452932\n",
      "       0      0      0      0      0]\n",
      " [  7941   1529      8    101    188      0    218      0      0      1\n",
      "  443810      0     12      0     23]\n",
      " [   100      0      0      0    170      0      0      0      0      0\n",
      "      96 454412     36      0      0]\n",
      " [   719      0      0    791      0      0     16      0      0      0\n",
      "       0     38 230348    782 221925]\n",
      " [     0      0      0      0      0      0      0      0      0      0\n",
      "       0      0    216 454289      0]\n",
      " [   583      0      0   2562      0      0      0      0      0      0\n",
      "       0      0  62485    551 388968]]\n"
     ]
    }
   ],
   "source": [
    "# Train an XGBoost classifier for fast initial detection\n",
    "# clf_xgb = xgb.XGBClassifier(eval_metric='logloss', use_label_encoder=False, random_state=42)\n",
    "clf_xgb = xgb.XGBClassifier(\n",
    "    eval_metric='logloss',  # Helps in classification\n",
    "    use_label_encoder=False,\n",
    "    max_depth=4,  # Reduce model complexity\n",
    "    min_child_weight=3,  # Prevent overfitting\n",
    "    gamma=0.2,  # Add tree complexity penalty\n",
    "    subsample=0.8,  # Randomly use 80% of data per tree\n",
    "    colsample_bytree=0.8,  # Use only 80% of features per tree\n",
    "    lambda_=1,  # L2 regularization\n",
    "    alpha=0.5,  # L1 regularization\n",
    "    learning_rate=0.05,  # Reduce step size for smoother convergence\n",
    "    n_estimators=200  # Reduce number of trees (test different values)\n",
    ")\n",
    "clf_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred_xgb = clf_xgb.predict(X_test)\n",
    "print(\"\\nXGBoost Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "print(\"XGBoost Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/john/Files/R&D Project/models/lib/python3.10/site-packages/xgboost/sklearn.py:1028: UserWarning: [21:59:48] WARNING: /workspace/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n"
     ]
    }
   ],
   "source": [
    "clf_xgb.save_model('second-ml-model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of uncertain predictions: 1733\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------- #\n",
    "# Step 5: Identify Uncertain Predictions\n",
    "# ---------------------------- #\n",
    "# Get the prediction probabilities for the positive class (assuming binary classification)\n",
    "y_probs = clf_xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Define uncertain predictions as those with probability in a narrow band (e.g., 0.45 to 0.55)\n",
    "uncertain_idx = np.where((y_probs > 0.45) & (y_probs < 0.55))[0]\n",
    "print(\"Number of uncertain predictions:\", len(uncertain_idx))\n",
    "\n",
    "# Extract uncertain samples and corresponding true labels\n",
    "X_uncertain = X_test[uncertain_idx]\n",
    "y_uncertain = y_test.iloc[uncertain_idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Training the DL model on CICIDS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# scaler_pca = MinMaxScaler(feature_range=(0, 1))  # Scale between 0 and 1\n",
    "# X_mi_scaled = scaler_pca.fit_transform(X_mi)\n",
    "\n",
    "# # Reshape for LSTM input (samples, time_steps, features)\n",
    "# X_mi_scaled = X_mi_scaled.reshape(X_mi_scaled.shape[0], 1, X_mi_scaled.shape[1])\n",
    "\n",
    "# Normalize features (LSTM benefits from scaling)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = X_train.shape[1]  # Number of features in input data\n",
    "\n",
    "X_train_reshaped = X_train_scaled.reshape(X_train_scaled.shape[0], 1, X_train_scaled.shape[1])\n",
    "X_test_reshaped = X_test_scaled.reshape(X_test_scaled.shape[0], 1, X_test_scaled.shape[1])\n",
    "\n",
    "num_classes = 15\n",
    "\n",
    "# history = lstm_model.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-03 02:26:40.166521: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "/home/john/Files/R&D Project/models/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------- #\n",
    "# Step 6: DL Model Training (LSTM) on Uncertain Samples\n",
    "# ---------------------------- #\n",
    "# Note: LSTMs typically require sequential data. For demonstration, we reshape each sample as a sequence of one timestep.\n",
    "# In real scenarios, you might form sequences from packet flows or time windows.\n",
    "\n",
    "# Reshape uncertain samples: shape becomes [samples, timesteps=1, features]\n",
    "# X_uncertain_reshaped = np.expand_dims(X_uncertain, axis=1)\n",
    "\n",
    "# Build a simple LSTM model\n",
    "# model_lstm = Sequential([\n",
    "#     LSTM(64, input_shape=(1, X_train.shape[1]), return_sequences=False),\n",
    "#     Dropout(0.2),\n",
    "#     Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "# Define LSTM model\n",
    "lstm_model = Sequential([\n",
    "    LSTM(128, return_sequences=True, input_shape=(1, num_features)),  \n",
    "    Dropout(0.3),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    LSTM(128, return_sequences=False),  \n",
    "    Dropout(0.3),\n",
    "    BatchNormalization(),\n",
    "\n",
    "    Dense(64, activation='relu'),  \n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(num_classes, activation='softmax')  \n",
    "])\n",
    "\n",
    "# Compile with categorical cross-entropy\n",
    "lstm_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# model_lstm.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m425871/425873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6895 - loss: 0.8260"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m425873/425873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1686s\u001b[0m 4ms/step - accuracy: 0.6895 - loss: 0.8260 - val_accuracy: 0.8274 - val_loss: 0.4152\n",
      "Epoch 2/10\n",
      "\u001b[1m425873/425873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1704s\u001b[0m 4ms/step - accuracy: 0.7870 - loss: 0.5349 - val_accuracy: 0.8182 - val_loss: 0.4281\n",
      "Epoch 3/10\n",
      "\u001b[1m425873/425873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1699s\u001b[0m 4ms/step - accuracy: 0.8027 - loss: 0.4902 - val_accuracy: 0.8180 - val_loss: 0.4646\n",
      "Epoch 4/10\n",
      "\u001b[1m425866/425873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8112 - loss: 0.4663"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m425873/425873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1700s\u001b[0m 4ms/step - accuracy: 0.8112 - loss: 0.4663 - val_accuracy: 0.8517 - val_loss: 0.3550\n",
      "Epoch 5/10\n",
      "\u001b[1m425873/425873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1688s\u001b[0m 4ms/step - accuracy: 0.8168 - loss: 0.4504 - val_accuracy: 0.8355 - val_loss: 0.3975\n",
      "Epoch 6/10\n",
      "\u001b[1m425873/425873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1685s\u001b[0m 4ms/step - accuracy: 0.8213 - loss: 0.4382 - val_accuracy: 0.8370 - val_loss: 0.3852\n",
      "Epoch 7/10\n",
      "\u001b[1m425873/425873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1696s\u001b[0m 4ms/step - accuracy: 0.8247 - loss: 0.4281 - val_accuracy: 0.8289 - val_loss: 0.3675\n",
      "Epoch 8/10\n",
      "\u001b[1m425871/425873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8276 - loss: 0.4196"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m425873/425873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2138s\u001b[0m 5ms/step - accuracy: 0.8276 - loss: 0.4196 - val_accuracy: 0.8493 - val_loss: 0.3430\n",
      "Epoch 9/10\n",
      "\u001b[1m425873/425873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1642s\u001b[0m 4ms/step - accuracy: 0.8301 - loss: 0.4125 - val_accuracy: 0.8532 - val_loss: 0.3480\n",
      "Epoch 10/10\n",
      "\u001b[1m425873/425873\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1647s\u001b[0m 4ms/step - accuracy: 0.8323 - loss: 0.4064 - val_accuracy: 0.8525 - val_loss: 0.3503\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_uncertain_reshaped' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 10\u001b[0m\n\u001b[1;32m      4\u001b[0m model_checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_lstm_model.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m history \u001b[38;5;241m=\u001b[39m lstm_model\u001b[38;5;241m.\u001b[39mfit(X_train_reshaped, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, \n\u001b[1;32m      7\u001b[0m                          validation_data\u001b[38;5;241m=\u001b[39m(X_test_reshaped, y_test), \n\u001b[1;32m      8\u001b[0m                          callbacks\u001b[38;5;241m=\u001b[39m[early_stop, model_checkpoint])\n\u001b[0;32m---> 10\u001b[0m predictions \u001b[38;5;241m=\u001b[39m lstm_model\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mX_uncertain_reshaped\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_uncertain_reshaped' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint(\"best_lstm_model.h5\", save_best_only=True)\n",
    "\n",
    "history = lstm_model.fit(X_train_reshaped, y_train, epochs=10, batch_size=64, \n",
    "                         validation_data=(X_test_reshaped, y_test), \n",
    "                         callbacks=[early_stop, model_checkpoint])\n",
    "\n",
    "predictions = lstm_model.predict(X_uncertain_reshaped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the LSTM model on the uncertain samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4314 - loss: -3.7943\n",
      "Epoch 2/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4404 - loss: -4.7083\n",
      "Epoch 3/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4197 - loss: -4.6447\n",
      "Epoch 4/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4273 - loss: -4.3579\n",
      "Epoch 5/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4225 - loss: -6.3256\n",
      "Epoch 6/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4205 - loss: -7.9194\n",
      "Epoch 7/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4021 - loss: -9.2234 \n",
      "Epoch 8/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4306 - loss: -9.1504\n",
      "Epoch 9/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4365 - loss: -6.3618\n",
      "Epoch 10/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4198 - loss: -10.0664\n",
      "Epoch 11/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4443 - loss: -5.9241\n",
      "Epoch 12/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4406 - loss: -7.6279\n",
      "Epoch 13/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4492 - loss: -11.0803\n",
      "Epoch 14/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4389 - loss: -14.3534\n",
      "Epoch 15/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4457 - loss: -9.6831\n",
      "Epoch 16/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4510 - loss: -12.4215\n",
      "Epoch 17/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4424 - loss: -15.1379\n",
      "Epoch 18/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4509 - loss: -11.3141\n",
      "Epoch 19/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4321 - loss: -12.9984\n",
      "Epoch 20/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4494 - loss: -17.4055\n",
      "Epoch 21/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4583 - loss: -24.6357\n",
      "Epoch 22/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4376 - loss: -14.0393\n",
      "Epoch 23/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4493 - loss: -6.8925\n",
      "Epoch 24/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4529 - loss: -19.1525\n",
      "Epoch 25/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4709 - loss: -16.8612\n",
      "Epoch 26/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4693 - loss: -18.8024\n",
      "Epoch 27/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4495 - loss: -18.4870\n",
      "Epoch 28/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4686 - loss: -17.9591\n",
      "Epoch 29/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4774 - loss: -11.8377\n",
      "Epoch 30/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4706 - loss: -17.8087\n",
      "Epoch 31/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4677 - loss: -18.4598\n",
      "Epoch 32/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4681 - loss: -19.4378\n",
      "Epoch 33/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4577 - loss: -19.3517\n",
      "Epoch 34/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4611 - loss: -25.7369\n",
      "Epoch 35/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4594 - loss: -16.9311\n",
      "Epoch 36/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4697 - loss: -16.4550\n",
      "Epoch 37/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4829 - loss: -15.2409\n",
      "Epoch 38/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4585 - loss: -15.3812\n",
      "Epoch 39/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4858 - loss: -26.4835\n",
      "Epoch 40/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4697 - loss: -27.8468\n",
      "Epoch 41/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4738 - loss: -23.8565\n",
      "Epoch 42/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4607 - loss: -26.6626\n",
      "Epoch 43/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.4716 - loss: -29.4773\n",
      "Epoch 44/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4678 - loss: -21.6103\n",
      "Epoch 45/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4874 - loss: -26.8567\n",
      "Epoch 46/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4706 - loss: -32.2276\n",
      "Epoch 47/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4676 - loss: -12.8150\n",
      "Epoch 48/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4911 - loss: -28.4449\n",
      "Epoch 49/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4634 - loss: -27.0590\n",
      "Epoch 50/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4737 - loss: -34.2943\n",
      "Epoch 51/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4757 - loss: -26.7638\n",
      "Epoch 52/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4766 - loss: -30.4923\n",
      "Epoch 53/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4860 - loss: -25.8309\n",
      "Epoch 54/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4663 - loss: -30.4121\n",
      "Epoch 55/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4615 - loss: -35.6729\n",
      "Epoch 56/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4984 - loss: -45.1167\n",
      "Epoch 57/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4730 - loss: -37.9010\n",
      "Epoch 58/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4677 - loss: -25.8668\n",
      "Epoch 59/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4615 - loss: -34.2573\n",
      "Epoch 60/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4606 - loss: -42.5370\n",
      "Epoch 61/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4807 - loss: -36.4444\n",
      "Epoch 62/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4729 - loss: -42.8544\n",
      "Epoch 63/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4663 - loss: -30.0798\n",
      "Epoch 64/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4645 - loss: -44.3816\n",
      "Epoch 65/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4608 - loss: -38.8329\n",
      "Epoch 66/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4817 - loss: -31.8967\n",
      "Epoch 67/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4734 - loss: -33.0940\n",
      "Epoch 68/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4697 - loss: -49.8525\n",
      "Epoch 69/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4788 - loss: -46.9912\n",
      "Epoch 70/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4799 - loss: -39.1615\n",
      "Epoch 71/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4724 - loss: -38.4328\n",
      "Epoch 72/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4768 - loss: -36.3460\n",
      "Epoch 73/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4855 - loss: -36.2243\n",
      "Epoch 74/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4626 - loss: -43.7161\n",
      "Epoch 75/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4916 - loss: -24.1448\n",
      "Epoch 76/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4671 - loss: -45.9856\n",
      "Epoch 77/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4666 - loss: -36.2947\n",
      "Epoch 78/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4732 - loss: -41.1308\n",
      "Epoch 79/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4635 - loss: -48.3470\n",
      "Epoch 80/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4883 - loss: -51.2191\n",
      "Epoch 81/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4760 - loss: -52.4826\n",
      "Epoch 82/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4825 - loss: -37.9643\n",
      "Epoch 83/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4829 - loss: -46.2231\n",
      "Epoch 84/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4612 - loss: -36.5099\n",
      "Epoch 85/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4958 - loss: -54.8767\n",
      "Epoch 86/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4928 - loss: -48.6517\n",
      "Epoch 87/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4747 - loss: -51.6525\n",
      "Epoch 88/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4721 - loss: -47.6348\n",
      "Epoch 89/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4976 - loss: -50.2080\n",
      "Epoch 90/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4918 - loss: -26.7537\n",
      "Epoch 91/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4572 - loss: -23.3669\n",
      "Epoch 92/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4814 - loss: -41.0542\n",
      "Epoch 93/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4875 - loss: -47.7235\n",
      "Epoch 94/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4874 - loss: -39.6029\n",
      "Epoch 95/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4695 - loss: -55.6000\n",
      "Epoch 96/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4837 - loss: -54.4048\n",
      "Epoch 97/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4748 - loss: -44.1343\n",
      "Epoch 98/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4798 - loss: -41.9674\n",
      "Epoch 99/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4759 - loss: -56.8515\n",
      "Epoch 100/100\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4663 - loss: -61.8214\n",
      "\u001b[1m55/55\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "LSTM Classification Report on Uncertain Samples:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.11      0.19       848\n",
      "           1       0.45      1.00      0.62       742\n",
      "          10       0.00      0.00      0.00       143\n",
      "\n",
      "    accuracy                           0.48      1733\n",
      "   macro avg       0.48      0.37      0.27      1733\n",
      "weighted avg       0.68      0.48      0.36      1733\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/john/Files/R&D Project/models/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/john/Files/R&D Project/models/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/john/Files/R&D Project/models/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# (In a production system, you would train the DL model on a dedicated set; here we train on uncertain samples for refinement)\n",
    "if len(X_uncertain_reshaped) > 0:\n",
    "    history = lstm_model.fit(X_uncertain_reshaped, y_uncertain, epochs=100, batch_size=32, verbose=1)\n",
    "    \n",
    "    # Evaluate the LSTM model on the uncertain set\n",
    "    y_pred_lstm_prob = lstm_model.predict(X_uncertain_reshaped)\n",
    "    y_pred_lstm = (y_pred_lstm_prob > 0.5).astype(int).flatten()\n",
    "    print(\"\\nLSTM Classification Report on Uncertain Samples:\")\n",
    "    print(classification_report(y_uncertain, y_pred_lstm))\n",
    "else:\n",
    "    print(\"No uncertain samples found; consider adjusting the uncertainty threshold.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
